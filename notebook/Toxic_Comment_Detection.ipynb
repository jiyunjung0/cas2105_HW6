{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 822,
     "referenced_widgets": [
      "79c853f850e440aa952f310f4fe74957",
      "89362278acfa42d5a6e07709ec7086d5",
      "632d975c6ddc412697513e7f0b443c44",
      "5495f757fe62401bbc66d79299008d4e",
      "b43577a1f34649f5a576e1f6db4734da",
      "27c4028755f9446ca968101e84ee95c5",
      "6d7491e3478b4b9d99158a4364ea52d0",
      "c4bb26a5f6af490399a9ff37c6d540d8",
      "d97efb82912f4c1d864ca68917bcfe78",
      "623623946630481fb5ee746f63017712",
      "762ec0c37c6740c6a97e416feab91068",
      "3894055c61814952a2f06ac2f5a6b9d3",
      "97abcbdfecc64b539cb998814721c976",
      "12a4de089d6c4cfd8fdbb0d8fb0aa242",
      "074f765650b54ddd950aa991433218fa",
      "c645163131ee4d91805d6a849a3912cb",
      "fb44baba73cc4dd58aea8f5ef0c13875",
      "bc9b7910406f454b8de6ed8431eb1846",
      "f760dc16562b4c2ca1cac8b2a2769c6a",
      "066887f57e2d42adab46de88e2a8d883",
      "a1c1d9ba19574f0a9aafe8319fc6100b",
      "1bb8f36d5b6c4ddf8db671c5460645af",
      "e11b16af68b64984baf612b4f9a161e4",
      "bb5ba3e3d6f04305833515b71d4c05fe",
      "73635d85e4a44e8294b7cd6d6f332522",
      "d969d0e1a8ad4de2b1c8e642bb765983",
      "ba2796817de94b5584d98d6f8046f85b",
      "9e9d51541f0a4845ae1ee140c48024f5",
      "3b3c27d10589433a8314932e5e334b11",
      "5fc6b8d815a24d849882f941da5abe80",
      "ff9ad539cc6f4f4a9a7faf441a5ecd49",
      "f6e97afb72e54483844d466484daa2a5",
      "06ad699e6ebb4f9b8dbfd2676a119ead",
      "3a23c3ef64674ece96a70a03371841ca",
      "45ccf1bffb004b009388dcb438283136",
      "dffdb9d0333f45b0854606fdc3a486d6",
      "a46413ecd4224967850c033f600db3f2",
      "94666eb004114f1a85721b8205324e4c",
      "452d3d9e74e3420fbcd5e5a5dd4d1e93",
      "4646f0f3efa044b881df063e7c2564b8",
      "c69cb0f00c994218b7b9e422647d9ee6",
      "bb7c625a7ac045a481e166ac562cf102",
      "9b68c90e98d94d9c8e322119f027d9c9",
      "7996373ce9d949769e2cd60832740299",
      "cca5670345934b29812fd1c7c22d746e",
      "24aad7b7bb7c4cfaa315900732dc5764",
      "46d7f9656d114407b8cc0a2e78d416ae",
      "3bf84d29241b4dc9b18edc706386024e",
      "e4505cfc17e54bebb003269f5979e7e3",
      "ef230d18cd0246a5ba96c6e7b83363da",
      "1a95e5287d4e45cd8e007650fb800014",
      "d4ab1b1752db4beabab3fa851dfb8de6",
      "4de7868b6a9b41b58183ac943b003b08",
      "c19d925c05b448f38d65979606a964f0",
      "7677304f88d843f993020e4e8660a4a5",
      "e628ca5006ea4b90a1c090690e9a0af5",
      "2cf3978ea3114486bc509e7f1324d06b",
      "9b75e9ef7a8545c18c326a996a47716e",
      "644f8164ecb9481e9f027ffe5d5e4b67",
      "f51817f786064193b0c1709a66ccea54",
      "5b3469b3aca54540903b7a0cf5c6db3e",
      "3556f8d3cb93476696a71f48da658cb8",
      "e6240939cd8b46b0956b338fc0a579ff",
      "a6b87820b6c04d63a93ad2fb928ae8a3",
      "aba16b890006405d91ab77d3a34fd3f5",
      "8ed414d7759148f9a56f2352723f4971",
      "3cf02c703f0345a0b32e748f552f0a24",
      "943b0a0d4cc64e758dc417d5c620d414",
      "4b7d4e9fa4b3428a9a0585cce85c7936",
      "9c066eaf9d834011990c25bd55fccbae",
      "7b2be6c43ff2489481fbf5c7ea065057",
      "547ecae983104de193f874cec6c0d8d3",
      "2687cadb7f4545188e052310afda745c",
      "4ce7df34df324d22a802e71b8697617a",
      "fc9d842c344b43aebca394696c798018",
      "2c2a74693d494d099d5d9259b4d6783c",
      "c0d1d36e66014d649c7a4594c96468a3"
     ]
    },
    "id": "9TZSVviyOCH-",
    "outputId": "53084367-0cda-4f1b-bd5d-64403a909b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading Balanced Dataset (50 Toxic / 50 Non-toxic)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c853f850e440aa952f310f4fe74957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Loaded: 100 examples (Balanced: 50 Toxic)\n",
      ">>> Running AI Pipeline (approx. 1-2 min)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3894055c61814952a2f06ac2f5a6b9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11b16af68b64984baf612b4f9a161e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a23c3ef64674ece96a70a03371841ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca5670345934b29812fd1c7c22d746e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e628ca5006ea4b90a1c090690e9a0af5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf02c703f0345a0b32e748f552f0a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      " [Results] Baseline Accuracy:   0.61\n",
      " [Results] AI Pipeline Accuracy: 0.86\n",
      "----------------------------------------\n",
      " [Results] Baseline F1 Score:   0.40\n",
      " [Results] AI Pipeline F1 Score: 0.84\n",
      "========================================\n",
      "\n",
      ">>> [Failure Cases: Baseline Failed vs. AI Succeeded]\n",
      "\n",
      "[Case Index 3]\n",
      "Comment: \"They are terrorists pure and simple....\"\n",
      " - True Label:      Toxic\n",
      " - Baseline Pred:   Non-toxic (Incorrect)\n",
      " - AI Pipeline Pred:Toxic (Correct)\n",
      "\n",
      "[Case Index 5]\n",
      "Comment: \"I honestly cannot decide if these guys are complete morons or the most patriotic hero's this country has seen in a long time....\"\n",
      " - True Label:      Toxic\n",
      " - Baseline Pred:   Non-toxic (Incorrect)\n",
      " - AI Pipeline Pred:Toxic (Correct)\n",
      "\n",
      "[Case Index 8]\n",
      "Comment: \"Their ridiculous band photo has me wanting to drink white wine at 3 in the afternoon.\n",
      "It's almost 5, right?...\"\n",
      " - True Label:      Toxic\n",
      " - Baseline Pred:   Non-toxic (Incorrect)\n",
      " - AI Pipeline Pred:Toxic (Correct)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers==4.30.0 datasets scikit-learn pandas > /dev/null 2>&1\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, disable_progress_bar\n",
    "from transformers import pipeline, logging as hf_logging\n",
    "\n",
    "os.environ[\"HF_HUB_DISABLE_PROGRESS_BARS\"] = \"1\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "hf_logging.set_verbosity_error()\n",
    "disable_progress_bar()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(\">>> Loading Balanced Dataset (50 Toxic / 50 Non-toxic)...\")\n",
    "\n",
    "dataset_stream = load_dataset(\"google/civil_comments\", split=\"train\", streaming=True)\n",
    "\n",
    "toxic_ds = list(dataset_stream.filter(lambda x: x['toxicity'] >= 0.5).take(50))\n",
    "nontoxic_ds = list(dataset_stream.filter(lambda x: x['toxicity'] < 0.5).take(50))\n",
    "\n",
    "dataset = toxic_ds + nontoxic_ds\n",
    "data = pd.DataFrame(dataset)\n",
    "\n",
    "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "data['label'] = data['toxicity'].apply(lambda x: 1 if x >= 0.5 else 0)\n",
    "\n",
    "print(f\"Data Loaded: {len(data)} examples (Balanced: {data['label'].sum()} Toxic)\")\n",
    "\n",
    "def naive_baseline(text):\n",
    "    text = text.lower()\n",
    "    bad_words = [\"stupid\", \"idiot\", \"dumb\", \"shut up\", \"trash\", \"kill\", \"ugly\", \"fat\", \"hell\", \"crazy\"]\n",
    "    if any(w in text for w in bad_words):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['baseline_pred'] = data['text'].apply(naive_baseline)\n",
    "\n",
    "print(\">>> Running AI Pipeline (approx. 1-2 min)...\")\n",
    "\n",
    "toxicity_model = pipeline(\"text-classification\", model=\"s-nlp/roberta_toxicity_classifier\", device=-1)\n",
    "\n",
    "def run_ai(text):\n",
    "    truncated_text = text[:512]\n",
    "    result = toxicity_model(truncated_text)[0]\n",
    "\n",
    "    if result['label'] == 'toxic':\n",
    "        return 1\n",
    "    elif result['label'] == 'neutral':\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 if result['score'] > 0.5 else 0\n",
    "\n",
    "data['ai_pred'] = data['text'].apply(run_ai)\n",
    "\n",
    "baseline_acc = accuracy_score(data['label'], data['baseline_pred'])\n",
    "ai_acc = accuracy_score(data['label'], data['ai_pred'])\n",
    "\n",
    "baseline_f1 = f1_score(data['label'], data['baseline_pred'])\n",
    "ai_f1 = f1_score(data['label'], data['ai_pred'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\" [Results] Baseline Accuracy:   {baseline_acc:.2f}\")\n",
    "print(f\" [Results] AI Pipeline Accuracy: {ai_acc:.2f}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\" [Results] Baseline F1 Score:   {baseline_f1:.2f}\")\n",
    "print(f\" [Results] AI Pipeline F1 Score: {ai_f1:.2f}\")\n",
    "print(\"=\"*40 + \"\\n\")\n",
    "\n",
    "\n",
    "print(\">>> [Failure Cases: Baseline Failed vs. AI Succeeded]\")\n",
    "diff = data[(data['baseline_pred'] != data['label']) & (data['ai_pred'] == data['label'])]\n",
    "\n",
    "for i, row in diff.head(3).iterrows():\n",
    "    print(f\"\\n[Case Index {i}]\")\n",
    "    print(f\"Comment: \\\"{row['text'][:200]}...\\\"\")\n",
    "    print(f\" - True Label:      {'Toxic' if row['label']==1 else 'Non-toxic'}\")\n",
    "    print(f\" - Baseline Pred:   {'Toxic' if row['baseline_pred']==1 else 'Non-toxic'} (Incorrect)\")\n",
    "    print(f\" - AI Pipeline Pred:{'Toxic' if row['ai_pred']==1 else 'Non-toxic'} (Correct)\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
